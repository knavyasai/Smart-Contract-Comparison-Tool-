# -*- coding: utf-8 -*-
"""Smart Contract Comparsion Tool .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11_WF9Tm9io4xu5BqnhNqALvp0wKDhkep
"""

!pip install PyMuPDF
!pip install python-docx

import pandas as pd
import fitz
import docx
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os
from tqdm import tqdm
import nltk
import spacy

# Ensure necessary nltk packages are downloaded
nltk.download("punkt")

# load spacy language model
nlp = spacy.load("en_core_web_sm")

# Function to read PDF files
def read_pdf(file_path):
    doc = fitz.open(file_path)
    paragraphs = []
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        paragraphs.extend(page.get_text("blocks"))
    return [p[4].strip() for p in paragraphs if p[4].strip()]

# Function to read docx files
def read_docx(file_path):
    doc = docx.document(file_path)
    paragraphs = [para.text.strip() for para in doc.paragraphs if para.text.strip()]
    return paragraphs

# Function to read files based on their extension
def read_file(file_path):
    if file_path.endswith('.pdf'):
        return read_pdf(file_path)
    elif file_path.endswith('.docx'):
        return read_docx(file_path)
    else:
        raise ValueError("Unsupported file format: {}".format(file_path))

def summarize_differences(text1, text2):
    doc1 = nlp(text1)
    doc2 = nlp(text2)
    sentences1 = [sent.text for sent in doc1.sents]
    sentences2 = [sent.text for sent in doc2.sents]
    combined_sentences = sentences1 + sentences2

    unique_sentences = list(set(combined_sentences))
def summarize_differences(text1, text2):
    # ... previous code block ...

    # Find entities and important keywords
    entities1 = set([ent.text for ent in doc1.ents])
    entities2 = set([ent.text for ent in doc2.ents])
    keywords1 = set([token.text for token in doc1 if token.is_alpha and not token.is_stop])
    keywords2 = set([token.text for token in doc2 if token.is_alpha and not token.is_stop])
    differences = (keywords1 | keywords2) - (keywords1 & keywords2)

    # ... next code block ...

    # Construct summary
    summary_sentences = []
    for sent in unique_sentences:
        if any(keyword in sent for keyword in differences) or any(entity in sent for entity in (entities1 | entities2)):
            summary_sentences.append(sent)

    summary = " ".join(summary_sentences[:3]) # Limit to first 3 sentences as summary
    return summary

# Main function to process contracts
def process_contracts(folder_path):
    files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf') or f.endswith('.docx')]
    results = []

    for i in tqdm(range(len(files))):
        for j in range(i+1, len(files)):
            paragraphs1 = read_file(files[i])
            paragraphs2 = read_file(files[j])
            # Corrected indentation here
            comparisons = compute_similarity(paragraphs1, paragraphs2)

            for para1, para2, similarity in comparisons:
                summary = summarize_differences(para1, para2)
                results.append((os.path.basename(files[i]) + " & " + os.path.basename(files[j]), para1, para2, similarity, summary))

    df = pd.DataFrame(results, columns=['Documents Compared', 'Paragraph 1', 'Paragraph 2', 'Similarity Score', 'Summary'])
    df.to_csv('contract_comparison_results.csv', index=False)
    return df

def compute_similarity(paragraphs1, paragraphs2, threshold=0.3):
    if not paragraphs1 or not paragraphs2:
        return []

    # Combine all paragraphs to fit the vectorizer
    all_texts = paragraphs1 + paragraphs2
    if not all_texts:
        return []

    vectorizer = TfidfVectorizer().fit(all_texts)

    # Transform each set of paragraphs
    tfidf_matrix1 = vectorizer.transform(paragraphs1)
    tfidf_matrix2 = vectorizer.transform(paragraphs2)

    comparisons = []
    # Compare each paragraph from doc1 with each from doc2
    for i, para1_vec in enumerate(tfidf_matrix1):
        for j, para2_vec in enumerate(tfidf_matrix2):
            # Compute cosine similarity between the two paragraph vectors
            similarity = cosine_similarity(para1_vec, para2_vec)[0][0]
            if similarity >= threshold:
                comparisons.append((paragraphs1[i], paragraphs2[j], similarity))
    return comparisons

import os
folder_path = '/content/sample_data/'
os.makedirs(folder_path, exist_ok=True)

# This will list the files the code sees. Ensure contract1.pdf, etc., are in this list.
print(os.listdir(folder_path))

# Set the folder path and process the contracts
folder_path = '/content/sample_data/' # Using the absolute path for robustness in Colab
result_df = process_contracts(folder_path)
print(result_df)

# Display link to download the CSV file in Colab
from google.colab import files
files.download('contract_comparison_results.csv')